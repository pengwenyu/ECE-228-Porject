{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eachann\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annotations_all.json', 'kmeans_for_anchors.py', 'LICENSE', 'predict.py', 'README.md', 'requirements.txt', 'test.ipynb', 'Train.ipynb', 'train.py', 'yolo.py']\n",
      "************************************************************\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------#\n",
    "#       对数据集进行训练\n",
    "# -------------------------------------#\n",
    "import os\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from nets.yolo4 import YoloBody\n",
    "from nets.yolo_training import LossHistory, YOLOLoss, weights_init\n",
    "# from utils.dataloader import YoloDataset, yolo_dataset_collate\n",
    "from utils.coco import COCO, yolo_dataset_collate, COCOEval\n",
    "from utils.utilss import DecodeBox, non_max_suppression, add_weight_decay, setup_seed\n",
    "from utils.summary import Summary\n",
    "import shutil\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['annotations_all.json', 'kmeans_for_anchors.py', 'LICENSE', 'predict.py', 'README.md', 'requirements.txt', 'test.ipynb', 'Train.ipynb', 'train.py', 'yolo.py']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tt100k_151_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eachann\\Desktop\\228\\tt100k_2021\\yolov4-TT100k\\Train.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m([f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(f)])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mtt100k_151_classes.txt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000003?line=2'>3</a>\u001b[0m     f\u001b[39m.\u001b[39mreadline()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tt100k_151_classes.txt'"
     ]
    }
   ],
   "source": [
    "print([f for f in os.listdir('.') if os.path.isfile(f)])\n",
    "with open('tt100k_151_classes.txt') as f:\n",
    "    f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yolo_decodes = []\n",
    "confidence = 0.01\n",
    "iou = 0.5\n",
    "g_steps = 0\n",
    "\n",
    "\n",
    "# ---------------------------------------------------#\n",
    "#   获得类和先验框\n",
    "# ---------------------------------------------------#\n",
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape([-1, 3, 2])[::-1, :, :]\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def fit_one_epoch(net, yolo_loss, epoch, epoch_size, epoch_size_val, gen, genval, Epoch, cuda):\n",
    "    total_loss = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    net.train()\n",
    "    print('Start Train')\n",
    "    with tqdm(total=epoch_size, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3) as pbar:\n",
    "        for iteration, batch in enumerate(gen):\n",
    "            if iteration >= epoch_size:\n",
    "                break\n",
    "            # images, targets = batch[0], batch[1]\n",
    "            img_ids, images, targets = batch[0], batch[1], batch[2]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if cuda:\n",
    "                    images = torch.from_numpy(images).type(torch.FloatTensor).cuda()\n",
    "                    targets = [torch.from_numpy(ann).type(torch.FloatTensor) for ann in targets]\n",
    "                else:\n",
    "                    images = torch.from_numpy(images).type(torch.FloatTensor)\n",
    "                    targets = [torch.from_numpy(ann).type(torch.FloatTensor) for ann in targets]\n",
    "            # ----------------------#\n",
    "            #   清零梯度\n",
    "            # ----------------------#\n",
    "            optimizer.zero_grad()\n",
    "            # ----------------------#\n",
    "            #   前向传播\n",
    "            # ----------------------#\n",
    "            outputs = net(images)\n",
    "            losses = []\n",
    "            num_pos_all = 0\n",
    "            # ----------------------#\n",
    "            #   计算损失\n",
    "            # ----------------------#\n",
    "            for i in range(3):\n",
    "                loss_item, num_pos = yolo_loss(outputs[i], targets)\n",
    "                losses.append(loss_item)\n",
    "                num_pos_all += num_pos\n",
    "\n",
    "            loss = sum(losses) / num_pos_all\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ----------------------#\n",
    "            #   反向传播\n",
    "            # ----------------------#\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            summary.add_scalar('train/total_loss', total_loss / (iteration + 1), epoch * epoch_size + iteration)\n",
    "            pbar.set_postfix(**{'total_loss': total_loss / (iteration + 1),\n",
    "                                'lr': get_lr(optimizer)})\n",
    "            pbar.update(1)\n",
    "    train_loss += [total_loss / (iteration + 1)]\n",
    "    net.eval()\n",
    "    print('Start Validation')\n",
    "    with torch.no_grad():\n",
    "        img_ids = []\n",
    "        detections = []\n",
    "        with tqdm(total=epoch_size_val, desc=f'Epoch {epoch + 1}/{Epoch}', postfix=dict, mininterval=0.3) as pbar:\n",
    "            for iteration, batch in enumerate(genval):\n",
    "                if iteration >= epoch_size_val:\n",
    "                    break\n",
    "                # images_val, targets_val = batch[0], batch[1]\n",
    "                img_ids_val, images_val, targets_val = batch[0], batch[1], batch[2]\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    if cuda:\n",
    "                        images_val = torch.from_numpy(images_val).type(torch.FloatTensor).cuda()\n",
    "                        targets_val = [torch.from_numpy(ann).type(torch.FloatTensor) for ann in targets_val]\n",
    "                    else:\n",
    "                        images_val = torch.from_numpy(images_val).type(torch.FloatTensor)\n",
    "                        targets_val = [torch.from_numpy(ann).type(torch.FloatTensor) for ann in targets_val]\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = net(images_val)\n",
    "\n",
    "                    # ----------------------#\n",
    "                    #   计算mAP\n",
    "                    # ----------------------#\n",
    "                    output_list = []\n",
    "                    for ii in range(3):\n",
    "                        output_list.append(yolo_decodes[ii](outputs[ii]))\n",
    "\n",
    "                    output = torch.cat(output_list, 1)\n",
    "                    batch_detections = non_max_suppression(output, num_classes, conf_thres=confidence,\n",
    "                                                           nms_thres=iou)\n",
    "                    # -----------------------------------debug---------------------------------\n",
    "                    # import cv2\n",
    "                    # images = images_val.squeeze().cpu().numpy()\n",
    "                    # images = np.transpose(np.clip(images * 255.0, 0, 255), (1, 2, 0)).astype(np.uint8)\n",
    "                    # cv2.imshow(\"images\", images)\n",
    "                    # cv2.waitKey()\n",
    "                    # print(img_ids_val, batch_detections)\n",
    "                    # -----------------------------------debug---------------------------------\n",
    "                    img_ids += img_ids_val\n",
    "                    detections += batch_detections\n",
    "\n",
    "                    losses = []\n",
    "                    num_pos_all = 0\n",
    "                    for i in range(3):\n",
    "                        loss_item, num_pos = yolo_loss(outputs[i], targets_val)\n",
    "                        losses.append(loss_item)\n",
    "                        num_pos_all += num_pos\n",
    "                    loss = sum(losses) / num_pos_all\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                # 将loss写入tensorboard, 下面注释的是每一步都写\n",
    "                # if Tensorboard:\n",
    "                #     writer.add_scalar('Val_loss', loss, val_tensorboard_step)\n",
    "                #     val_tensorboard_step += 1\n",
    "                summary.add_scalar('val/total_loss', val_loss / (iteration + 1), epoch * epoch_size + iteration)\n",
    "                pbar.set_postfix(**{'total_loss': val_loss / (iteration + 1)})\n",
    "                pbar.update(1)\n",
    "\n",
    "        loss_history.append_loss(total_loss / (epoch_size + 1), val_loss / (epoch_size_val + 1))\n",
    "        val_loss += [total_loss / (epoch_size + 1)]\n",
    "        eval_results = val_dataset.run_eval(img_ids, detections)\n",
    "        print(\"RRRRRREEEEESSSSSSS\",eval_results)\n",
    "        summary.add_scalar('val/mAP', eval_results[0], epoch + 1)\n",
    "\n",
    "        print('Finish Validation')\n",
    "        print('Epoch:' + str(epoch + 1) + '/' + str(Epoch))\n",
    "        print(eval_results)\n",
    "        print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss / (epoch_size + 1), val_loss / (epoch_size_val + 1)))\n",
    "\n",
    "        net_save_path = os.path.join(os.path.join(exp_dir, \"ckpt\"), \"model_latest.pth\")\n",
    "        net_save_path_best = os.path.join(os.path.join(exp_dir, \"ckpt\"), \"model_data/model_best.pth\")\n",
    "\n",
    "        save_best = False\n",
    "        if eval_results[0] >= metrics['mAP']:\n",
    "            save_best = True\n",
    "            metrics['train_loss'] = total_loss / (epoch_size + 1)\n",
    "            metrics['val_loss'] = val_loss / (epoch_size_val + 1)\n",
    "            metrics['mAP'] = eval_results[0]\n",
    "            metrics['best_model_epoch'] = epoch + 1\n",
    "            print('Saving state, iter:', str(epoch + 1))\n",
    "\n",
    "        torch.save({\"state_dict\": model.state_dict(),\n",
    "                    \"metric\": metrics}\n",
    "                   , net_save_path)\n",
    "\n",
    "        if save_best:\n",
    "            shutil.copy(net_save_path, net_save_path_best)\n",
    "            print(\"Saving current best: {}, metric:{}\".format(net_save_path_best, metrics))\n",
    "\n",
    "        print(\"@@@ best metric:{}\".format(net_save_path_best, metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available True\n",
      "['annotations_all.json', 'kmeans_for_anchors.py', 'LICENSE', 'predict.py', 'README.md', 'requirements.txt', 'test.ipynb', 'Train.ipynb', 'train.py', 'yolo.py']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yolov4-TT100k/model_data/tt100k_151_classes.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eachann\\Desktop\\228\\tt100k_2021\\yolov4-TT100k\\Train.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=43'>44</a>\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmAP\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mbest_model_epoch\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=44'>45</a>\u001b[0m \u001b[39m# ----------------------------------------------------#\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=45'>46</a>\u001b[0m \u001b[39m#   获取classes和anchor\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=46'>47</a>\u001b[0m \u001b[39m# ----------------------------------------------------#\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=47'>48</a>\u001b[0m class_names \u001b[39m=\u001b[39m get_classes(classes_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=48'>49</a>\u001b[0m anchors \u001b[39m=\u001b[39m get_anchors(anchors_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000002?line=49'>50</a>\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(class_names)\n",
      "\u001b[1;32mc:\\Users\\Eachann\\Desktop\\228\\tt100k_2021\\yolov4-TT100k\\Train.ipynb Cell 2'\u001b[0m in \u001b[0;36mget_classes\u001b[1;34m(classes_path)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000001?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_classes\u001b[39m(classes_path):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000001?line=10'>11</a>\u001b[0m     \u001b[39m'''loads the classes'''\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000001?line=11'>12</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(classes_path) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000001?line=12'>13</a>\u001b[0m         class_names \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eachann/Desktop/228/tt100k_2021/yolov4-TT100k/Train.ipynb#ch0000001?line=13'>14</a>\u001b[0m     class_names \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m class_names]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov4-TT100k/model_data/tt100k_151_classes.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------------#\n",
    "#   检测精度mAP和pr曲线计算参考视频\n",
    "#   https://www.bilibili.com/video/BV1zE411u7Vw\n",
    "# ----------------------------------------------------#\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    setup_seed(1215)\n",
    "    # -------------------------------#\n",
    "    #   是否使用Cuda\n",
    "    #   没有GPU可以设置成False\n",
    "    # -------------------------------#\n",
    "    print(\"CUDA available\",torch.cuda.is_available())\n",
    "    Cuda = True\n",
    "    # ------------------------------------------------------#\n",
    "    #   是否对损失进行归一化，用于改变loss的大小\n",
    "    #   用于决定计算最终loss是除上batch_size还是除上正样本数量\n",
    "    # ------------------------------------------------------#\n",
    "    normalize = False\n",
    "    # -------------------------------#\n",
    "    #   输入的shape大小\n",
    "    #   显存比较小可以使用416x416\n",
    "    #   显存比较大可以使用608x608\n",
    "    # -------------------------------#\n",
    "    # input_shape = (416, 416)\n",
    "    input_shape = (608, 608)\n",
    "    # ----------------------------------------------------#\n",
    "    #   classes和anchor的路径，非常重要\n",
    "    #   训练前一定要修改classes_path，使其对应自己的数据集\n",
    "    # ----------------------------------------------------#\n",
    "    anchors_path = 'yolov4-TT100k/model_data/yolo_anchors.txt'\n",
    "    classes_path = 'yolov4-TT100k/model_data/tt100k_151_classes.txt'\n",
    "    print([f for f in os.listdir('.') if os.path.isfile(f)])\n",
    "    # ------------------------------------------------------#\n",
    "    #   Yolov4的tricks应用\n",
    "    #   mosaic 马赛克数据增强 True or False \n",
    "    #   实际测试时mosaic数据增强并不稳定，所以默认为False\n",
    "    #   Cosine_scheduler 余弦退火学习率 True or False\n",
    "    #   label_smoothing 标签平滑 0.01以下一般 如0.01、0.005\n",
    "    # ------------------------------------------------------#\n",
    "    mosaic = False\n",
    "    Cosine_lr = True\n",
    "    smoooth_label = 0.005\n",
    "    weight_decay = 1e-5\n",
    "    metrics = {'mAP': 0, 'train_loss': float('inf'), 'val_loss': float('inf'), 'best_model_epoch': 0}\n",
    "    # ----------------------------------------------------#\n",
    "    #   获取classes和anchor\n",
    "    # ----------------------------------------------------#\n",
    "    class_names = get_classes(classes_path)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # ----------------------------------------------------#\n",
    "\n",
    "    for i in range(3):\n",
    "        yolo_decodes.append(\n",
    "            DecodeBox(anchors[i], num_classes, (input_shape[1], input_shape[0])))\n",
    "\n",
    "    # ------------------------------------------------------#\n",
    "    #   创建yolo模型\n",
    "    #   训练前一定要修改classes_path和对应的txt文件\n",
    "    # ------------------------------------------------------#\n",
    "    model = YoloBody(len(anchors[0]), num_classes)\n",
    "    weights_init(model)\n",
    "\n",
    "    # ------------------------------------------------------#\n",
    "    #   权值文件请看README，百度网盘下载\n",
    "    # ------------------------------------------------------#\n",
    "    #model_path = \"model_data/yolo4_weights.pth\"\n",
    "    #model_path = \"exp/exp_baseline/ckpt/model_best.pth\"\n",
    "    model_path =  'yolov4-TT100k/model_data/model_best.pth'\n",
    "    print('Loading weights into state dict...')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = torch.load(model_path, map_location=device)[\"state_dict\"]\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) == np.shape(v)}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    print('Finished!')\n",
    "\n",
    "    net = model.train()\n",
    "\n",
    "    if Cuda:\n",
    "        net = torch.nn.DataParallel(model)\n",
    "        cudnn.benchmark = True\n",
    "        net = net.cuda()\n",
    "\n",
    "    yolo_loss = YOLOLoss(np.reshape(anchors, [-1, 2]), num_classes, (input_shape[1], input_shape[0]), smoooth_label,\n",
    "                         Cuda, normalize)\n",
    "    exp_dir = \"./exp/exp_baseline_mosaic\"\n",
    "    loss_history = LossHistory(exp_dir)\n",
    "    summary = Summary(os.path.join(exp_dir, \"summary\"))\n",
    "    ckpt = os.path.join(exp_dir, \"ckpt\")\n",
    "    if not os.path.exists(ckpt):\n",
    "        os.makedirs(ckpt)\n",
    "\n",
    "    if Cuda:\n",
    "        graph_inputs = torch.randn(1, 3, input_shape[0], input_shape[1]).type(torch.FloatTensor).cuda()\n",
    "    else:\n",
    "        graph_inputs = torch.randn(1, 3, input_shape[0], input_shape[1]).type(torch.FloatTensor)\n",
    "    summary.add_graph(model, graph_inputs)\n",
    "\n",
    "    # ----------------------------------------------------#\n",
    "    #   获得图片路径和标签\n",
    "    # ----------------------------------------------------#\n",
    "    data_dir = \"../tt100k/\"\n",
    "\n",
    "    # ------------------------------------------------------#\n",
    "    #   主干特征提取网络特征通用，冻结训练可以加快训练速度\n",
    "    #   也可以在训练初期防止权值被破坏。\n",
    "    #   Init_Epoch为起始世代\n",
    "    #   Freeze_Epoch为冻结训练的世代\n",
    "    #   Epoch总训练世代\n",
    "    #   提示OOM或者显存不足请调小Batch_size\n",
    "    # ------------------------------------------------------#\n",
    "    if True:\n",
    "        lr = 1e-3\n",
    "        Batch_size = 32\n",
    "        Init_Epoch = 0\n",
    "        Freeze_Epoch = 30\n",
    "\n",
    "        # ----------------------------------------------------------------------------#\n",
    "        #   YOLOv5代码中，conv层和FC层的bias参数，以及BN层的参数并不进行权重衰减，此处采用这个方法\n",
    "        # ----------------------------------------------------------------------------#\n",
    "        parameters = add_weight_decay(net, weight_decay)\n",
    "        optimizer = optim.Adam(parameters, lr)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr)\n",
    "\n",
    "        if Cosine_lr:\n",
    "            lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "        else:\n",
    "            lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.92)\n",
    "\n",
    "        train_dataset = COCO(data_dir, (input_shape[0], input_shape[1]), mosaic=mosaic)\n",
    "        val_dataset = COCOEval(data_dir, (input_shape[0], input_shape[1]))\n",
    "        # train_dataset = YoloDataset(lines[:num_train], (input_shape[0], input_shape[1]), mosaic=mosaic, is_train=True)\n",
    "        # val_dataset = YoloDataset(lines[num_train:], (input_shape[0], input_shape[1]), mosaic=False, is_train=False)\n",
    "        gen = DataLoader(train_dataset, shuffle=True, batch_size=Batch_size, num_workers=4, pin_memory=True,\n",
    "                         drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "        gen_val = DataLoader(val_dataset, shuffle=True, batch_size=Batch_size, num_workers=4, pin_memory=True,\n",
    "                             drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "\n",
    "        epoch_size = len(train_dataset) // Batch_size\n",
    "        epoch_size_val = len(val_dataset) // Batch_size\n",
    "\n",
    "        if epoch_size == 0 or epoch_size_val == 0:\n",
    "            raise ValueError(\"数据集过小，无法进行训练，请扩充数据集。\")\n",
    "\n",
    "        # ------------------------------------#\n",
    "        #   冻结一定部分训练\n",
    "        # ------------------------------------#\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for epoch in range(Init_Epoch, Freeze_Epoch):\n",
    "            fit_one_epoch(net, yolo_loss, epoch, epoch_size, epoch_size_val, gen, gen_val, Freeze_Epoch, Cuda)\n",
    "            lr_scheduler.step()\n",
    "\n",
    "    # Releases all unoccupied cached memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if True:\n",
    "        lr = 1e-4\n",
    "        Batch_size = 8\n",
    "        Freeze_Epoch = 30\n",
    "        Unfreeze_Epoch = 100\n",
    "\n",
    "        # ----------------------------------------------------------------------------#\n",
    "        #   我在实际测试时，发现optimizer的weight_decay起到了反作用，\n",
    "        #   所以去除掉了weight_decay，大家也可以开起来试试，一般是weight_decay=5e-4\n",
    "        # ----------------------------------------------------------------------------#\n",
    "        parameters = add_weight_decay(net, weight_decay)\n",
    "        optimizer = optim.Adam(parameters, lr)\n",
    "        # optimizer = optim.Adam(net.parameters(), lr)\n",
    "        if Cosine_lr:\n",
    "            lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
    "        else:\n",
    "            lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.92)\n",
    "\n",
    "        train_dataset = COCO(data_dir, (input_shape[0], input_shape[1]), mosaic=mosaic)\n",
    "        val_dataset = COCOEval(data_dir, (input_shape[0], input_shape[1]))\n",
    "        # train_dataset = YoloDataset(lines[:num_train], (input_shape[0], input_shape[1]), mosaic=mosaic, is_train=True)\n",
    "        # val_dataset = YoloDataset(lines[num_train:], (input_shape[0], input_shape[1]), mosaic=False, is_train=False)\n",
    "        gen = DataLoader(train_dataset, shuffle=True, batch_size=Batch_size, num_workers=4, pin_memory=True,\n",
    "                         drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "        gen_val = DataLoader(val_dataset, shuffle=True, batch_size=Batch_size, num_workers=4, pin_memory=True,\n",
    "                             drop_last=True, collate_fn=yolo_dataset_collate)\n",
    "\n",
    "        epoch_size = len(train_dataset) // Batch_size\n",
    "        epoch_size_val = len(val_dataset) // Batch_size\n",
    "\n",
    "        if epoch_size == 0 or epoch_size_val == 0:\n",
    "            raise ValueError(\"数据集过小，无法进行训练，请扩充数据集。\")\n",
    "\n",
    "        # ------------------------------------#\n",
    "        #   解冻后训练\n",
    "        # ------------------------------------#\n",
    "        for param in model.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for epoch in range(Freeze_Epoch, Unfreeze_Epoch):\n",
    "            fit_one_epoch(net, yolo_loss, epoch, epoch_size, epoch_size_val, gen, gen_val, Unfreeze_Epoch, Cuda)\n",
    "            lr_scheduler.step()\n",
    "torch.save(net.state_dict(), 'mymodel.pth')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4199c13b508d82d4f0006079c77b28de888f4ee301ff64a5dbc5b165bd2d999"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
